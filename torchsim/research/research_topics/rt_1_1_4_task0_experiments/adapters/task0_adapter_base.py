import math
from abc import abstractmethod
from typing import List

import torch

from torchsim.core.eval.metrics.sp_convergence_metrics import average_sp_delta, average_boosting_duration
from torchsim.core.eval.node_accessors.flock_node_accessor import FlockNodeAccessor
from torchsim.core.eval.node_accessors.random_number_accessor import RandomNumberNodeAccessor
from torchsim.core.eval.node_accessors.se_io_accessor import SeIoAccessor
from torchsim.core.graph import Topology
from torchsim.core.nodes.expert_node import ExpertFlockNode
from torchsim.core.nodes.fork_node import ForkNode
from torchsim.core.nodes.random_number_node import RandomNumberNode
from torchsim.core.nodes.constant_node import ConstantNode
from torchsim.research.experiment_templates.task0_online_learning_template import Task0OnlineLearningAdapterBase
from torchsim.research.research_topics.rt_1_1_4_task0_experiments.topologies.task0_narrow_topology import Task0NarrowTopology
from torchsim.research.se_tasks.topologies.se_io.se_io_base import SeIoBase
from torchsim.research.se_tasks.topologies.se_io.se_io_task0_dataset import SeIoTask0Dataset


class Task0AdapterBase(Task0OnlineLearningAdapterBase):
    """Provides an insight into learned SP representations in the hierarchy of FLockNodes and a random baseline."""

    _topology: Task0NarrowTopology

    _se_io: SeIoBase
    _flock_nodes: List[ExpertFlockNode]  # layers of flocks
    _fork_node: ForkNode

    _baselines: List[RandomNumberNode]
    _label_baseline: ConstantNode
    _random_label_baseline: RandomNumberNode

    def set_topology(self, topology: Task0NarrowTopology):
        self._topology = topology

        self._se_io = self._topology.se_io
        self._baselines = self._topology.baselines
        self._flock_nodes = self._topology.flock_nodes
        self._label_baseline = self._topology.label_baseline
        self._random_label_baseline = self._topology.random_label_baseline
        self._fork_node = self._topology.fork_node

    def get_topology(self) -> Topology:
        return self._topology

    def get_label_id(self) -> int:
        return SeIoAccessor.get_label_id(self._se_io)

    def clone_label_tensor(self) -> torch.Tensor:
        return SeIoAccessor.get_label_tensor(self._se_io).clone()

    def clone_ground_truth_label_tensor(self) -> torch.Tensor:
        """The same as get_label_tensor, but this one is not hidden during testing (for computing stats)."""
        return SeIoAccessor.task_to_agent_label_ground_truth(self._se_io).clone()

    def clone_baseline_output_tensor_for_labels(self) -> torch.Tensor:
        return self._label_baseline.outputs.output.tensor.clone()

    def clone_random_baseline_output_tensor_for_labels(self) -> torch.Tensor:
        return RandomNumberNodeAccessor.get_output_tensor(self._random_label_baseline).clone()

    def clone_predicted_label_tensor_output(self) -> torch.Tensor:
        return self._fork_node.outputs[1].tensor.clone()

    def get_random_baseline_output_id_for_labels(self) -> int:
        """Returns index of 1 in the one-hot vector generated by the baseline which predicts the class labels."""
        return RandomNumberNodeAccessor.get_output_id(self._random_label_baseline)

    def get_baseline_output_id_for(self, layer_id: int) -> int:
        return RandomNumberNodeAccessor.get_output_id(self._baselines[layer_id])

    def get_sp_output_size_for(self, layer_id: int) -> int:
        return FlockNodeAccessor.get_sp_output_size(self._flock_nodes[layer_id])

    def clone_sp_output_tensor_for(self, layer_id: int) -> torch.Tensor:
            return FlockNodeAccessor.get_sp_output_tensor(self._flock_nodes[layer_id]).clone()

    def get_sp_output_id_for(self, layer_id: int) -> int:
        return FlockNodeAccessor.get_sp_output_id(self._flock_nodes[layer_id])

    # def is_output_id_available_for(self, layer_id: int) -> bool:
    #     """Only layers of flock_size=1 support output id """
    #     return self._flock_nodes[layer_id].params.flock_size == 1

    def get_average_log_delta_for(self, layer_id: int) -> float:
        """Average sp deltas for the entire flock in a given layer. Tensors not cloned!"""
        delta = average_sp_delta(
            FlockNodeAccessor.get_sp_deltas(self._flock_nodes[layer_id]))

        if delta > 0:  # avoid math.domain error
            delta = math.log(delta)
        return delta

    def get_average_boosting_duration_for(self, layer_id: int) -> float:
        return average_boosting_duration(
            FlockNodeAccessor.get_sp_boosting_durations(self._flock_nodes[layer_id]))

    def get_device(self) -> str:
        return self._topology.device

    def get_current_step(self) -> int:
        return self._topology.current_step

    def switch_learning(self, learning_on: bool):
        """Turn the learning on / off"""
        self._topology.switch_learning(learning_on)

    def dataset_switch_learning(self, learning_on: bool, just_hide_labels: bool):
        # SE probably do not support manual switching between train/test
        assert type(self._se_io) is SeIoTask0Dataset

        io_dataset: SeIoTask0Dataset = self._se_io
        io_dataset.node_se_dataset.switch_training(learning_on, just_hide_labels)

    def is_learning(self) -> bool:
        return self._topology.is_learning

    @abstractmethod
    def get_title(self) -> str:
        pass
