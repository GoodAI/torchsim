{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[2., 2., 2.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[3., 3., 3.],\n",
      "         [3., 3., 3.]],\n",
      "\n",
      "        [[4., 4., 4.],\n",
      "         [4., 4., 4.]]])\n",
      "torch.Size([5])\n",
      "tensor([1, 1, 2, 2, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def pt(t):\n",
    "    print(t.size())\n",
    "    print(t)\n",
    "\n",
    "labels = torch.Tensor([1, 1, 2, 2, 3]).byte()\n",
    "data = torch.stack([torch.full((2, 3), i) for i in range(5)])\n",
    "\n",
    "pt(data)\n",
    "pt(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n",
      "tensor([], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.]],\n",
       "\n",
       "        [[  1.,   2.,   3.],\n",
       "         [  1.,   2.,   3.]],\n",
       "\n",
       "        [[  2.,   4.,   6.],\n",
       "         [  2.,   4.,   6.]],\n",
       "\n",
       "        [[  3.,   6.,   9.],\n",
       "         [  3.,   6.,   9.]],\n",
       "\n",
       "        [[  4.,   8.,  12.],\n",
       "         [  4.,   8.,  12.]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = labels.apply_(lambda x: x == 2).nonzero().squeeze().long()\n",
    "pt(indices)\n",
    "# data.index_select(0, torch.Tensor([1,2]).long())\n",
    "data.index_select(0, indices)\n",
    "\n",
    "torch.cumsum(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mio is <class '__main__.MyImageObservable'>: True\n",
      "mio is <class '__main__.ImageObservable'>: True\n",
      "mio is <class '__main__.TextObservable'>: False\n"
     ]
    }
   ],
   "source": [
    "class Observable:\n",
    "    pass\n",
    "class ImageObservable(Observable):\n",
    "    pass\n",
    "class TextObservable(Observable):\n",
    "    pass\n",
    "\n",
    "class MyImageObservable(ImageObservable):pass\n",
    "\n",
    "switch = {\n",
    "  ImageObservable: 'io',\n",
    "  TextObservable: 'to'}\n",
    "\n",
    "def not_found(name, observable):\n",
    "  raise ValueError(f'Observer type \"{type(observable)}\" is not supported')\n",
    "\n",
    "io = ImageObservable()\n",
    "to = TextObservable()\n",
    "mio = MyImageObservable()\n",
    "\n",
    "\n",
    "# switch.get(type(observable), not_found)(name, observable)\n",
    "# switch.get(type(to))\n",
    "def t(name, obj, t):\n",
    "    print(f'{name} is {t}: {isinstance(obj, t)}')\n",
    "          \n",
    "t('mio', mio, MyImageObservable)\n",
    "t('mio', mio, ImageObservable)\n",
    "t('mio', mio, TextObservable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.]])\n",
      "[0, 0, 1, 1]\n",
      "[0, 0, 1, 1, 2, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2, 2],\n",
       "       [1, 1, 2, 2],\n",
       "       [3, 3, 4, 4],\n",
       "       [3, 3, 4, 4]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def pt(t):\n",
    "    print(t.size())\n",
    "    print(t)\n",
    "\n",
    "data = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "# data = torch.stack([torch.full((2, 3), i) for i in range(5)])\n",
    "\n",
    "pt(data)\n",
    "\n",
    "data[:,[0,0,0]][[0,0,1,1]]\n",
    "\n",
    "torch.linspace(0,4.5, steps=10).byte()\n",
    "[torch.linspace(0,x + 0.5, steps=x*2).byte() for x in data.size()]\n",
    "\n",
    "#[range for x in range(1,5)]\n",
    "\n",
    "scale = 2\n",
    "count = 4\n",
    "[v for x in range(count) for v in [x]*scale ]\n",
    "\n",
    "\n",
    "def get_indices(size: int):\n",
    "    return [v for x in range(size) for v in [x]*scale]\n",
    "\n",
    "x = get_indices(data.size()[0])\n",
    "y = get_indices(data.size()[1])\n",
    "# data[get_indices(data.size[0])][get_indices(data.size[1])]\n",
    "print(x)\n",
    "print(y)\n",
    "data[:,y][x]\n",
    "\n",
    "np.array([\n",
    "            [1, 1, 2, 2],\n",
    "            [1, 1, 2, 2],\n",
    "            [3, 3, 4, 4],\n",
    "            [3, 3, 4, 4],\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "torch.Size([2, 4])\n",
      "tensor([[-1.,  1., -2.,  0.],\n",
      "        [ 0.,  2.,  4.,  0.]])\n",
      "\n",
      "filter\n",
      "torch.Size([2, 4])\n",
      "tensor([[ 0,  1,  0,  0],\n",
      "        [ 0,  1,  1,  0]], dtype=torch.uint8)\n",
      "\n",
      "target\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 1.0000,  0.0000,  0.5000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 1.0000,  0.0000,  0.5000],\n",
      "         [ 1.0000,  0.0000,  0.5000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]])\n",
      "\n",
      "v\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[-1.0000, -0.0000, -0.5000],\n",
      "         [ 1.0000,  0.0000,  0.5000],\n",
      "         [-2.0000, -0.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 2.0000,  0.0000,  1.0000],\n",
      "         [ 4.0000,  0.0000,  2.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def p(name, t):\n",
    "    print(name)\n",
    "    print(t.size())\n",
    "    print(t)\n",
    "    print('')\n",
    "\n",
    "\n",
    "data = torch.Tensor([[-1, 1, -2, 0], [0, 2, 4, 0]])\n",
    "min = -2\n",
    "max = 2\n",
    "\n",
    "filter = (data > 0).byte()\n",
    "indices = filter.nonzero()\n",
    "p('data', data)\n",
    "p('filter', filter)\n",
    "# p('indices', indices)\n",
    "\n",
    "target = torch.zeros((2, 4, 3))\n",
    "# target=data.clone()\n",
    "target[filter] = torch.Tensor([1,0,0.5])\n",
    "# target[filter] = 100\n",
    "# target=data[:,:,None]\n",
    "\n",
    "# target[0, 0, :] = torch.Tensor([1,2,3])\n",
    "\n",
    "p('target', target)\n",
    "\n",
    "# v = target * data.unsqueeze(2)\n",
    "v = data.unsqueeze(2) * torch.Tensor([1,0,0.5])\n",
    "\n",
    "p('v', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got float)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-13c41007d55b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: new(): data must be a sequence (got float)"
     ]
    }
   ],
   "source": [
    "torch.Tensor(float(\"nan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 2]\n",
      " [0 1 3]\n",
      " [0 0 1]]\n",
      "[[1 0 4]\n",
      " [0 1 5]\n",
      " [0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 6],\n",
       "       [0, 1, 8],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,0,2],[0,1,3], [0,0,1]])\n",
    "b = np.array([[1,0,4],[0,1,5], [0,0,1]])\n",
    "#b = np.array([[0,0,4],[0,0,5], [0,0,0]])\n",
    "print(a)\n",
    "print(b)\n",
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 1]])\n",
      "torch.Size([3, 2, 2])\n",
      "tensor([[[ 0.,  1.],\n",
      "         [ 2.,  3.]],\n",
      "\n",
      "        [[ 4.,  5.],\n",
      "         [ 6.,  7.]],\n",
      "\n",
      "        [[ 8.,  9.],\n",
      "         [10., 11.]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 4: Index tensor must have same dimensions as input tensor at c:\\a\\w\\1\\s\\tmp_conda_3.7_061434\\conda\\conda-bld\\pytorch_1544163540495\\work\\aten\\src\\th\\generic/THTensorEvenMoreMath.cpp:438",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0e566cd8e928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# out.scatter_(1, freq_seq, imgs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 4: Index tensor must have same dimensions as input tensor at c:\\a\\w\\1\\s\\tmp_conda_3.7_061434\\conda\\conda-bld\\pytorch_1544163540495\\work\\aten\\src\\th\\generic/THTensorEvenMoreMath.cpp:438"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "freq_seq = torch.Tensor([[[0,1,2], [0,1,1]]]).long().view((2,3))\n",
    "imgs = torch.arange(0, 4*3).view((3,4)).float()\n",
    "pt(freq_seq)\n",
    "pt(imgs)\n",
    "\n",
    "# out = torch.zeros((2,3))\n",
    "# out.scatter_(1, freq_seq, imgs)\n",
    "\n",
    "out = torch.gather(imgs, 0, freq_seq)\n",
    "pt(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
