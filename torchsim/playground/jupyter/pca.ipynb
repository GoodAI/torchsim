{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "    [0,0,0,0,0],\n",
    "    [2,0,0,4,0],\n",
    "    [4,0,0,8,0],\n",
    "    [6,0,0,12,0],\n",
    "    [8,0,0,16,0],\n",
    "])\n",
    "\n",
    "data2 = np.array([\n",
    "    [0,0,0,0,10],\n",
    "    [2,0,0,4,20],\n",
    "    [4,0,0,8,30],\n",
    "    [6,0,0,12,20],\n",
    "    [8,0,0,16,10],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# n = 2000\n",
    "# dim = 64 * 64\n",
    "# data = torch.randn(n, dim, device=\"cuda\", dtype=torch.float)\n",
    "\n",
    "\n",
    "def pca(data: torch.Tensor, target_dimension: int):\n",
    "    # normalize data\n",
    "    means = data.mean(dim=0)\n",
    "    std_devs = data.std(dim=0, unbiased=True)\n",
    "    std_devs[std_devs == 0] = 1\n",
    "    data_normalized = (data - means) / std_devs\n",
    "    _, _, V = data_normalized.svd(some=True)\n",
    "    V = V[:, :target_dimension]\n",
    "    return V, means, std_devs\n",
    "\n",
    "def project(data: torch.Tensor, pca_matrix: torch.Tensor, means, std_devs):\n",
    "    # normalize data with means and std_devs obtained from \"training\" data\n",
    "    data_normalized = (data - means) / std_devs\n",
    "    projected = data_normalized.mm(pca_matrix)\n",
    "#     if dimensionality == 2:\n",
    "#         projected[:, 2] = 0\n",
    "    return projected\n",
    "\n",
    "tdata = torch.tensor(data2).float()\n",
    "V, means, std_devs = pca(tdata, 2)\n",
    "print(V)\n",
    "result = project(tdata, V, means, std_devs)\n",
    "\n",
    "print(result)\n",
    "# data_normalized = (tdata - means) / std_devs\n",
    "# print(data_normalized)\n",
    "# data_normalized.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "x = StandardScaler().fit_transform(data2)\n",
    "result = pca.fit_transform(x)\n",
    "# principalDf = pd.DataFrame(data = principalComponents\n",
    "#              , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "# print(x)\n",
    "# x.var()\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
